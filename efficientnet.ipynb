{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bbd29b3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4461ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c27c3c4",
   "metadata": {},
   "source": [
    "## Logs\n",
    "##### Function to log the training metrics\n",
    "###### (Change the path name in `log_path` as required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d75ccd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "log_path = \"logs/trainingFullData_log.csv\"\n",
    "with open(log_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['epoch', 'train_loss', 'train_accuracy', 'val_loss', 'val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "219a86d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b33aeb7",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8dfeba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from C:/Users/moksh/OneDrive/Desktop/Alzeimers/Alzeimers-detection/dataset/train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "demented: 100%|██████████| 146/146 [00:06<00:00, 21.93it/s]\n",
      "non-demented: 100%|██████████| 152/152 [00:07<00:00, 21.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 298 samples in 13.77s\n",
      "Loading data from C:/Users/moksh/OneDrive/Desktop/Alzeimers/Alzeimers-detection/dataset/val...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "demented: 100%|██████████| 37/37 [00:01<00:00, 21.36it/s]\n",
      "non-demented: 100%|██████████| 38/38 [00:01<00:00, 21.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 75 samples in 3.49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define your transform (modify as needed)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converts HWC NumPy -> CHW Tensor\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                         std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Load MRI volumes into a list\n",
    "def load_npy_data(root_dir):\n",
    "    samples = []\n",
    "    print(f\"Loading data from {root_dir}...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    for label in os.listdir(root_dir):\n",
    "        label_path = os.path.join(root_dir, label)\n",
    "        if os.path.isdir(label_path):\n",
    "            for file in tqdm(os.listdir(label_path), desc=label):\n",
    "                full_path = os.path.join(label_path, file)\n",
    "                vol = np.load(full_path)  # (20, H, W)\n",
    "                vol = np.repeat(vol[:, :, :, None], 3, axis=3)  # (20, H, W, 3)\n",
    "                \n",
    "                # Apply transforms to each slice\n",
    "                vol_tensor = torch.stack([transform(slice) for slice in vol])  # (20, 3, H, W)\n",
    "                label_val = 0 if label == \"demented\" else 1\n",
    "                samples.append((vol_tensor, label_val))\n",
    "    \n",
    "    print(f\"✅ Loaded {len(samples)} samples in {time.time() - start:.2f}s\")\n",
    "    return samples\n",
    "\n",
    "train_dataset = load_npy_data(r\"C:/Users/moksh/OneDrive/Desktop/Alzeimers/Alzeimers-detection/dataset/train\")\n",
    "val_dataset = load_npy_data(r\"C:/Users/moksh/OneDrive/Desktop/Alzeimers/Alzeimers-detection/dataset/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "196eb53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0d29c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Label Distribution: Counter({1: 152, 0: 146})\n",
      "Validation Set Label Distribution: Counter({1: 38, 0: 37})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Check label distribution in training set\n",
    "train_labels = [label for _, label in train_dataset]\n",
    "val_labels = [label for _, label in val_dataset]\n",
    "\n",
    "print(\"Training Set Label Distribution:\", Counter(train_labels))\n",
    "print(\"Validation Set Label Distribution:\", Counter(val_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8b8bdc",
   "metadata": {},
   "source": [
    "## Load the Model (Efficientnet-B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6ed5d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moksh\\AppData\\Local\\Temp\\ipykernel_20620\\2920788952.py:18: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "c:\\Users\\moksh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = EfficientNet.from_pretrained(\"efficientnet-b2\")\n",
    "feature_dim = model._fc.in_features\n",
    "model._fc = nn.Identity()\n",
    "\n",
    "classifier = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(feature_dim, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(512, 2)\n",
    ")\n",
    "\n",
    "model = nn.Sequential(model, classifier).to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scaler = GradScaler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e096536",
   "metadata": {},
   "source": [
    "## Train from a save\n",
    "##### Run the below cell if you want to train from a saved state. Change the path inside `torch.load()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"checkpoint_epoch_10.pt\")  # or checkpoint_epoch_8.pt\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "scaler.load_state_dict(checkpoint['scaler_state'])\n",
    "start_epoch = checkpoint['epoch'] + 1  # Resume from next epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4afbef3",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "###### Increase or decrease the patience accrodingly. The model tends to plateau at the beginning and will suddenely generalize well, after which it will start to overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "949eb09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/25:   0%|          | 0/149 [00:00<?, ?it/s]C:\\Users\\moksh\\AppData\\Local\\Temp\\ipykernel_20620\\2554771436.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 1/25: 100%|██████████| 149/149 [17:52<00:00,  7.20s/it]\n",
      "C:\\Users\\moksh\\AppData\\Local\\Temp\\ipykernel_20620\\2554771436.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 1] Train Loss: 0.6747 | Acc: 57.38% | Time: 1072.2s\n",
      "           Val Loss:   0.7560 | Acc: 50.67%\n",
      "Best val accuracy model saved.\n",
      "Best generalization model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/25: 100%|██████████| 149/149 [17:45<00:00,  7.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 2] Train Loss: 0.5875 | Acc: 68.79% | Time: 1065.5s\n",
      "           Val Loss:   0.8076 | Acc: 50.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/25: 100%|██████████| 149/149 [17:45<00:00,  7.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 3] Train Loss: 0.5572 | Acc: 70.13% | Time: 1065.2s\n",
      "           Val Loss:   0.6494 | Acc: 54.67%\n",
      "Best val accuracy model saved.\n",
      "Best generalization model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/25: 100%|██████████| 149/149 [17:32<00:00,  7.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 4] Train Loss: 0.5041 | Acc: 73.83% | Time: 1052.8s\n",
      "           Val Loss:   0.8562 | Acc: 50.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/25:   2%|▏         | 3/149 [00:26<21:32,  8.86s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 95\u001b[0m\n\u001b[0;32m     92\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39mstate_dict()}, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_epoch.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal model saved as last_epoch.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 95\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 30\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(num_epochs, start_epoch, patience)\u001b[0m\n\u001b[0;32m     27\u001b[0m     out \u001b[38;5;241m=\u001b[39m model[\u001b[38;5;241m1\u001b[39m](mean_features)\n\u001b[0;32m     28\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(out, y)\n\u001b[1;32m---> 30\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[0;32m     32\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[1;32mc:\\Users\\moksh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\moksh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\moksh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "File \u001b[1;32mc:\\Users\\moksh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\function.py:292\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBackwardCFunction\u001b[39;00m(_C\u001b[38;5;241m.\u001b[39m_FunctionBase, FunctionCtx, _HookMixin):\n\u001b[0;32m    288\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;124;03m    This class is used for internal autograd work. Do not use.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 292\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m    293\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;124;03m        Apply method used when executing this Node during the backward\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[0;32m    296\u001b[0m         \u001b[38;5;66;03m# _forward_cls is defined by derived class\u001b[39;00m\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# The user should define either backward or vjp but never both.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(num_epochs=25, start_epoch=1, patience=7):\n",
    "    best_val_acc = 0\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_since_improvement = 0\n",
    "\n",
    "    # Ensure CSV log starts clean\n",
    "    if not os.path.exists(log_path):\n",
    "        with open(log_path, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['epoch', 'train_loss', 'train_acc', 'val_loss', 'val_acc'])\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs + 1):\n",
    "        model.train()\n",
    "        epoch_start = time.time()\n",
    "        total_loss, total_correct, total_samples = 0, 0, 0\n",
    "\n",
    "        for x, y in tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs}\"):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            B, S, C, H, W = x.shape\n",
    "            x = x.view(B * S, C, H, W).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                features = model[0].extract_features(x)\n",
    "                pooled = nn.AdaptiveAvgPool2d(1)(features).view(B, S, -1)\n",
    "                mean_features = pooled.mean(dim=1)\n",
    "                out = model[1](mean_features)\n",
    "                loss = criterion(out, y)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_correct += (out.argmax(1) == y).sum().item()\n",
    "            total_samples += y.size(0)\n",
    "\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        train_acc = 100 * total_correct / total_samples\n",
    "        print(f\"\\n[Epoch {epoch}] Train Loss: {train_loss:.4f} | Acc: {train_acc:.2f}% | Time: {time.time() - epoch_start:.1f}s\")\n",
    "\n",
    "        # === Validation ===\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_samples = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                B, S, C, H, W = x.shape\n",
    "                x = x.view(B * S, C, H, W).float()\n",
    "\n",
    "                with autocast():\n",
    "                    features = model[0].extract_features(x)\n",
    "                    pooled = nn.AdaptiveAvgPool2d(1)(features).view(B, S, -1)\n",
    "                    mean_features = pooled.mean(dim=1)\n",
    "                    out = model[1](mean_features)\n",
    "                    loss = criterion(out, y)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                val_correct += (out.argmax(1) == y).sum().item()\n",
    "                val_samples += y.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = 100 * val_correct / val_samples\n",
    "        print(f\"           Val Loss:   {val_loss:.4f} | Acc: {val_acc:.2f}%\")\n",
    "\n",
    "        # === Log to CSV ===\n",
    "        with open(log_path, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([epoch, train_loss, train_acc, val_loss, val_acc])\n",
    "\n",
    "        # === Save Best Accuracy Model ===\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save({'epoch': epoch, 'model_state': model.state_dict()}, 'best_val.pt')\n",
    "            print(\"Best val accuracy model saved.\")\n",
    "            epochs_since_improvement = 0\n",
    "        else:\n",
    "            epochs_since_improvement += 1\n",
    "\n",
    "        # === Save Best Generalization (lowest val loss) ===\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({'epoch': epoch, 'model_state': model.state_dict()}, 'best_generalization.pt')\n",
    "            print(\"Best generalization model saved.\")\n",
    "\n",
    "        # === Early Stopping Check ===\n",
    "        if epochs_since_improvement >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch} (no improvement for {patience} epochs).\")\n",
    "            break\n",
    "\n",
    "    # === Save Final Model ===\n",
    "    torch.save({'epoch': epoch, 'model_state': model.state_dict()}, 'last_epoch.pt')\n",
    "    print(\"Final model saved as last_epoch.pt\")\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d5a012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], \n",
    "                         [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "test_dir = \"dataset/test/\"\n",
    "\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    root=test_dir,\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,      \n",
    "    shuffle=False,       \n",
    "    num_workers=2,       \n",
    "    pin_memory=True      \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cfa1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.ImageFolder(\"dataset/test\", transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a50248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b2\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === Recreate the same model used during training ===\n",
    "model = EfficientNet.from_pretrained(\"efficientnet-b2\")\n",
    "feature_dim = model._fc.in_features\n",
    "model._fc = nn.Identity()\n",
    "\n",
    "classifier = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(feature_dim, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(512, 2)\n",
    ")\n",
    "\n",
    "model = nn.Sequential(model, classifier).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da3669c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 3 checkpoint(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omana\\AppData\\Local\\Temp\\ipykernel_26604\\2896019465.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(ckpt_path, map_location=device)\n",
      "Evaluating checkpoints/best_val.pt: 100%|██████████| 26/26 [00:08<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/best_val.pt: Test Acc = 36.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating checkpoints/best_generalization.pt: 100%|██████████| 26/26 [00:07<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/best_generalization.pt: Test Acc = 54.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating checkpoints/last_epoch.pt: 100%|██████████| 26/26 [00:08<00:00,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/last_epoch.pt: Test Acc = 33.46%\n",
      "\n",
      "🏆 Best Checkpoint:\n",
      "checkpoints/best_generalization.pt → 54.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([('checkpoints/best_val.pt', 36.385836385836384),\n",
       "  ('checkpoints/best_generalization.pt', 54.82295482295483),\n",
       "  ('checkpoints/last_epoch.pt', 33.45543345543345)],\n",
       " 'checkpoints/best_generalization.pt')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_checkpoint(ckpt_path, model, test_loader, device):\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(test_loader, desc=f\"Evaluating {ckpt_path}\"):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            out = model(x)\n",
    "            all_preds.append(out.softmax(dim=1).cpu().numpy())\n",
    "            all_labels.append(y.cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    pred_classes = np.argmax(all_preds, axis=1)\n",
    "    acc = (pred_classes == all_labels).mean() * 100\n",
    "\n",
    "    return acc\n",
    "\n",
    "\n",
    "def check_all_checkpoints(model, test_loader, device, ckpt_paths=None):\n",
    "    if ckpt_paths is None:\n",
    "        ckpt_paths = [\n",
    "            \"checkpoints/best_val.pt\",\n",
    "            \"checkpoints/best_generalization.pt\",\n",
    "            \"checkpoints/last_epoch.pt\"\n",
    "        ]\n",
    "\n",
    "    print(f\"Evaluating {len(ckpt_paths)} checkpoint(s)...\")\n",
    "\n",
    "    best_acc = 0\n",
    "    best_ckpt = None\n",
    "    results = []\n",
    "\n",
    "    for ckpt in ckpt_paths:\n",
    "        acc = evaluate_checkpoint(ckpt, model, test_loader, device)\n",
    "        results.append((ckpt, acc))\n",
    "        print(f\"{ckpt}: Test Acc = {acc:.2f}%\")\n",
    "        \n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_ckpt = ckpt\n",
    "\n",
    "    print(\"\\n🏆 Best Checkpoint:\")\n",
    "    print(f\"{best_ckpt} → {best_acc:.2f}%\")\n",
    "\n",
    "    return results, best_ckpt\n",
    "\n",
    "# Run this:\n",
    "check_all_checkpoints(model, test_loader, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
